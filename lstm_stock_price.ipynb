{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\pandas_datareader\\compat\\__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from pandas_datareader import data\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [],[]\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        dataX.append(dataset[i:(i+look_back),0])\n",
    "        dataY.append(dataset[i+look_back,0])\n",
    "        \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>208.190002</td>\n",
       "      <td>205.389999</td>\n",
       "      <td>207.990005</td>\n",
       "      <td>205.539993</td>\n",
       "      <td>130333800.0</td>\n",
       "      <td>185.170166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>206.880005</td>\n",
       "      <td>204.179993</td>\n",
       "      <td>206.380005</td>\n",
       "      <td>205.429993</td>\n",
       "      <td>121465900.0</td>\n",
       "      <td>185.071075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>204.369995</td>\n",
       "      <td>201.350006</td>\n",
       "      <td>204.169998</td>\n",
       "      <td>201.720001</td>\n",
       "      <td>169632600.0</td>\n",
       "      <td>181.728745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>202.720001</td>\n",
       "      <td>198.860001</td>\n",
       "      <td>202.089996</td>\n",
       "      <td>199.820007</td>\n",
       "      <td>209151400.0</td>\n",
       "      <td>180.017090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>202.720001</td>\n",
       "      <td>200.880005</td>\n",
       "      <td>201.419998</td>\n",
       "      <td>202.309998</td>\n",
       "      <td>125346700.0</td>\n",
       "      <td>182.260269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close       Volume  \\\n",
       "Date                                                                      \n",
       "2014-12-31  208.190002  205.389999  207.990005  205.539993  130333800.0   \n",
       "2015-01-02  206.880005  204.179993  206.380005  205.429993  121465900.0   \n",
       "2015-01-05  204.369995  201.350006  204.169998  201.720001  169632600.0   \n",
       "2015-01-06  202.720001  198.860001  202.089996  199.820007  209151400.0   \n",
       "2015-01-07  202.720001  200.880005  201.419998  202.309998  125346700.0   \n",
       "\n",
       "             Adj Close  \n",
       "Date                    \n",
       "2014-12-31  185.170166  \n",
       "2015-01-02  185.071075  \n",
       "2015-01-05  181.728745  \n",
       "2015-01-06  180.017090  \n",
       "2015-01-07  182.260269  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = datetime(2015,1,1,0,0,0,0,pytz.utc)\n",
    "end = datetime(2016,1,1,0,0,0,0,pytz.utc)\n",
    "spy = data.DataReader(\"SPY\",\"yahoo\",start,end)\n",
    "dataset = np.array(spy['Close'].values).reshape(-1,1)\n",
    "dataset = dataset.astype('float32')\n",
    "spy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset)*0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "look_back = 10\n",
    "X_train, y_train = create_dataset(train,look_back)\n",
    "X_test, y_test = create_dataset(test,look_back)\n",
    "#reshape for lstm[samples,timesteps,features]\n",
    "X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1],1))\n",
    "X_test = np.reshape(X_test,(X_test.shape[0], X_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "D:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(32, input_shape=(None, 1))`\n",
      "  \n",
      "D:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 4s - loss: 0.1194\n",
      "Epoch 2/100\n",
      " - 0s - loss: 0.0157\n",
      "Epoch 3/100\n",
      " - 0s - loss: 0.0125\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0123\n",
      "Epoch 5/100\n",
      " - 0s - loss: 0.0125\n",
      "Epoch 6/100\n",
      " - 0s - loss: 0.0118\n",
      "Epoch 7/100\n",
      " - 0s - loss: 0.0118\n",
      "Epoch 8/100\n",
      " - 0s - loss: 0.0115\n",
      "Epoch 9/100\n",
      " - 0s - loss: 0.0112\n",
      "Epoch 10/100\n",
      " - 0s - loss: 0.0117\n",
      "Epoch 11/100\n",
      " - 0s - loss: 0.0124\n",
      "Epoch 12/100\n",
      " - 0s - loss: 0.0110\n",
      "Epoch 13/100\n",
      " - 0s - loss: 0.0114\n",
      "Epoch 14/100\n",
      " - 0s - loss: 0.0108\n",
      "Epoch 15/100\n",
      " - 0s - loss: 0.0102\n",
      "Epoch 16/100\n",
      " - 0s - loss: 0.0113\n",
      "Epoch 17/100\n",
      " - 0s - loss: 0.0103\n",
      "Epoch 18/100\n",
      " - 0s - loss: 0.0096\n",
      "Epoch 19/100\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 20/100\n",
      " - 0s - loss: 0.0104\n",
      "Epoch 21/100\n",
      " - 0s - loss: 0.0097\n",
      "Epoch 22/100\n",
      " - 0s - loss: 0.0093\n",
      "Epoch 23/100\n",
      " - 0s - loss: 0.0090\n",
      "Epoch 24/100\n",
      " - 0s - loss: 0.0088\n",
      "Epoch 25/100\n",
      " - 0s - loss: 0.0085\n",
      "Epoch 26/100\n",
      " - 0s - loss: 0.0094\n",
      "Epoch 27/100\n",
      " - 0s - loss: 0.0087\n",
      "Epoch 28/100\n",
      " - 0s - loss: 0.0084\n",
      "Epoch 29/100\n",
      " - 0s - loss: 0.0080\n",
      "Epoch 30/100\n",
      " - 0s - loss: 0.0079\n",
      "Epoch 31/100\n",
      " - 0s - loss: 0.0084\n",
      "Epoch 32/100\n",
      " - 0s - loss: 0.0083\n",
      "Epoch 33/100\n",
      " - 0s - loss: 0.0078\n",
      "Epoch 34/100\n",
      " - 0s - loss: 0.0076\n",
      "Epoch 35/100\n",
      " - 0s - loss: 0.0073\n",
      "Epoch 36/100\n",
      " - 0s - loss: 0.0090\n",
      "Epoch 37/100\n",
      " - 0s - loss: 0.0072\n",
      "Epoch 38/100\n",
      " - 0s - loss: 0.0077\n",
      "Epoch 39/100\n",
      " - 0s - loss: 0.0073\n",
      "Epoch 40/100\n",
      " - 0s - loss: 0.0069\n",
      "Epoch 41/100\n",
      " - 0s - loss: 0.0068\n",
      "Epoch 42/100\n",
      " - 0s - loss: 0.0071\n",
      "Epoch 43/100\n",
      " - 0s - loss: 0.0075\n",
      "Epoch 44/100\n",
      " - 0s - loss: 0.0065\n",
      "Epoch 45/100\n",
      " - 0s - loss: 0.0066\n",
      "Epoch 46/100\n",
      " - 0s - loss: 0.0062\n",
      "Epoch 47/100\n",
      " - 0s - loss: 0.0062\n",
      "Epoch 48/100\n",
      " - 0s - loss: 0.0060\n",
      "Epoch 49/100\n",
      " - 0s - loss: 0.0059\n",
      "Epoch 50/100\n",
      " - 0s - loss: 0.0068\n",
      "Epoch 51/100\n",
      " - 0s - loss: 0.0067\n",
      "Epoch 52/100\n",
      " - 0s - loss: 0.0060\n",
      "Epoch 53/100\n",
      " - 0s - loss: 0.0061\n",
      "Epoch 54/100\n",
      " - 0s - loss: 0.0058\n",
      "Epoch 55/100\n",
      " - 0s - loss: 0.0060\n",
      "Epoch 56/100\n",
      " - 0s - loss: 0.0060\n",
      "Epoch 57/100\n",
      " - 0s - loss: 0.0060\n",
      "Epoch 58/100\n",
      " - 0s - loss: 0.0058\n",
      "Epoch 59/100\n",
      " - 0s - loss: 0.0057\n",
      "Epoch 60/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 61/100\n",
      " - 0s - loss: 0.0069\n",
      "Epoch 62/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 63/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 64/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 65/100\n",
      " - 0s - loss: 0.0053\n",
      "Epoch 66/100\n",
      " - 0s - loss: 0.0052\n",
      "Epoch 67/100\n",
      " - 0s - loss: 0.0055\n",
      "Epoch 68/100\n",
      " - 0s - loss: 0.0053\n",
      "Epoch 69/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 70/100\n",
      " - 0s - loss: 0.0056\n",
      "Epoch 71/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 72/100\n",
      " - 0s - loss: 0.0053\n",
      "Epoch 73/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 74/100\n",
      " - 0s - loss: 0.0058\n",
      "Epoch 75/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 76/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 77/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 78/100\n",
      " - 0s - loss: 0.0048\n",
      "Epoch 79/100\n",
      " - 0s - loss: 0.0053\n",
      "Epoch 80/100\n",
      " - 0s - loss: 0.0050\n",
      "Epoch 81/100\n",
      " - 0s - loss: 0.0050\n",
      "Epoch 82/100\n",
      " - 0s - loss: 0.0048\n",
      "Epoch 83/100\n",
      " - 0s - loss: 0.0050\n",
      "Epoch 84/100\n",
      " - 0s - loss: 0.0049\n",
      "Epoch 85/100\n",
      " - 0s - loss: 0.0052\n",
      "Epoch 86/100\n",
      " - 0s - loss: 0.0056\n",
      "Epoch 87/100\n",
      " - 0s - loss: 0.0053\n",
      "Epoch 88/100\n",
      " - 0s - loss: 0.0048\n",
      "Epoch 89/100\n",
      " - 0s - loss: 0.0049\n",
      "Epoch 90/100\n",
      " - 0s - loss: 0.0049\n",
      "Epoch 91/100\n",
      " - 0s - loss: 0.0048\n",
      "Epoch 92/100\n",
      " - 0s - loss: 0.0054\n",
      "Epoch 93/100\n",
      " - 0s - loss: 0.0049\n",
      "Epoch 94/100\n",
      " - 0s - loss: 0.0047\n",
      "Epoch 95/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 96/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 97/100\n",
      " - 0s - loss: 0.0047\n",
      "Epoch 98/100\n",
      " - 0s - loss: 0.0049\n",
      "Epoch 99/100\n",
      " - 0s - loss: 0.0051\n",
      "Epoch 100/100\n",
      " - 0s - loss: 0.0051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18a13185b48>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32,input_dim=1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "model.fit(X_train, y_train, nb_epoch=100, batch_size=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(X_train)\n",
    "test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.44796038 0.54746485 0.56385803 0.60274506 0.7178807  0.6747999\n 0.6930995  0.5897832  0.4906597  0.56118965 0.46435356 0.5585208\n 0.6698437  0.6401067  0.7186427  0.6969123  0.66183805 0.7449484\n 0.74952316 0.8253908  0.85817766 0.87075853 0.8715215  0.8658023\n 0.9138398  0.9126954  0.93557024 0.9287076  0.9191766  0.891727\n 0.9424329  0.9092641  0.8753333  0.88410234 0.77125454 0.8040414\n 0.6751809  0.65688133 0.7560048  0.70758677 0.81242895 0.78879166\n 0.88410234 0.8475032  0.88219595 0.8665652  0.821579   0.7049179\n 0.68623734 0.7041559  0.7998476  0.7304611  0.7026305  0.7308426\n 0.7838354  0.762867   0.7895541  0.82462835 0.86809015 0.831872\n 0.8471222  0.88295794 0.880671   0.7884102  0.860847   0.8513155\n 0.8905835  0.910789   0.9294696  0.89592123 0.92146444 0.8882966\n 0.8078542  0.89401484 0.91688967 0.82462835 0.7918415  0.8234844\n 0.92832613 0.8898206  0.8658023  0.86732817 0.95082045 0.9595885\n 0.9847503  0.9820819  0.97636366 1.0000005  0.98055696 0.8932519\n 0.969501   0.96035147 0.910027   0.9264207  0.9184146  0.93976355\n 0.8715215  0.85779667 0.80861616 0.8074722  0.9027829  0.9287076\n 0.86694574 0.83263445 0.87609625 0.8890586  0.97255087 0.89744616\n 0.9386201  0.9443383  0.88562727 0.8612275  0.85970306 0.69195604\n 0.7083497  0.77125454 0.7640109  0.74151754 0.79107904 0.65802526\n 0.67213106 0.7704916  0.85779667 0.89248896 0.8898206  0.9542508\n 0.96111345 0.96530676 0.9332824  0.9187951  0.8734269  0.7903166\n 0.7441859  0.841022   0.89592123 0.8978276  0.88562727 0.85855865\n 0.8429284  0.86923456 0.8036604  0.7884102  0.8882966  0.8158598\n 0.8253908  0.8154788  0.84445286 0.8890586  0.8658023  0.80251646\n 0.63667583 0.40259266 0.0850172  0.         0.27411413 0.45749187\n 0.45787287 0.39649248].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-89d3afaaf1bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[1;32m--> 434\u001b[1;33m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    554\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.44796038 0.54746485 0.56385803 0.60274506 0.7178807  0.6747999\n 0.6930995  0.5897832  0.4906597  0.56118965 0.46435356 0.5585208\n 0.6698437  0.6401067  0.7186427  0.6969123  0.66183805 0.7449484\n 0.74952316 0.8253908  0.85817766 0.87075853 0.8715215  0.8658023\n 0.9138398  0.9126954  0.93557024 0.9287076  0.9191766  0.891727\n 0.9424329  0.9092641  0.8753333  0.88410234 0.77125454 0.8040414\n 0.6751809  0.65688133 0.7560048  0.70758677 0.81242895 0.78879166\n 0.88410234 0.8475032  0.88219595 0.8665652  0.821579   0.7049179\n 0.68623734 0.7041559  0.7998476  0.7304611  0.7026305  0.7308426\n 0.7838354  0.762867   0.7895541  0.82462835 0.86809015 0.831872\n 0.8471222  0.88295794 0.880671   0.7884102  0.860847   0.8513155\n 0.8905835  0.910789   0.9294696  0.89592123 0.92146444 0.8882966\n 0.8078542  0.89401484 0.91688967 0.82462835 0.7918415  0.8234844\n 0.92832613 0.8898206  0.8658023  0.86732817 0.95082045 0.9595885\n 0.9847503  0.9820819  0.97636366 1.0000005  0.98055696 0.8932519\n 0.969501   0.96035147 0.910027   0.9264207  0.9184146  0.93976355\n 0.8715215  0.85779667 0.80861616 0.8074722  0.9027829  0.9287076\n 0.86694574 0.83263445 0.87609625 0.8890586  0.97255087 0.89744616\n 0.9386201  0.9443383  0.88562727 0.8612275  0.85970306 0.69195604\n 0.7083497  0.77125454 0.7640109  0.74151754 0.79107904 0.65802526\n 0.67213106 0.7704916  0.85779667 0.89248896 0.8898206  0.9542508\n 0.96111345 0.96530676 0.9332824  0.9187951  0.8734269  0.7903166\n 0.7441859  0.841022   0.89592123 0.8978276  0.88562727 0.85855865\n 0.8429284  0.86923456 0.8036604  0.7884102  0.8882966  0.8158598\n 0.8253908  0.8154788  0.84445286 0.8890586  0.8658023  0.80251646\n 0.63667583 0.40259266 0.0850172  0.         0.27411413 0.45749187\n 0.45787287 0.39649248].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "train_pred = scaler.inverse_transform(train_pred)\n",
    "y_train.reshape(1,-1)\n",
    "y_train = scaler.inverse_transform(y_train)\n",
    "test_pred = scaler.inverse_transform(test_pred)\n",
    "y_test = scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_plot = np.empty_like(dataset)\n",
    "train_pred_plot[:,:] = np.nan\n",
    "train_pred_plot[look_back:len(train_pred)+look_back,:] = train_pred\n",
    "\n",
    "test_pred_plot = np.empty_like(dataset)\n",
    "test_pred_plot[:,:] = np.nan\n",
    "test_pred_plot[len(train_pred)+(look_back*2)+1:len(dataset)-1,:] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(scaler.inverse_transform(dataset), color='b', lw=2.0, label='S&P 500')\n",
    "plt.plot(train_pred_plot, color='g', lw=2.0, label='LSTM train')\n",
    "plt.plot(test_pred_plot, color='r', lw=2.0, label='LSTM test')\n",
    "plt.legend(loc=3)\n",
    "plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
